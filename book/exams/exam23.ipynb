{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Correction of the exam 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "There were 5 exam questions:\n",
    "- 2 multiple choice\n",
    "- 1 short programming exercise\n",
    "- 2 longer notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Multiple choice: Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "**Which following statements about python packages and conda environments are true? Careful: wrongly ticked answers will give negative points!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "```{dropdown}  When a python package is installed in the base conda environment, it is also installed per default in any other conda environment.\n",
    "\n",
    "**Answer**: Wrong. Lecture notes on the topic: [](install-env)\n",
    "```\n",
    "\n",
    "```{dropdown} \"mamba install\" is very similar to \"conda install\", but is usually faster.\n",
    "\n",
    "**Answer**: Correct. Lecture notes on the topic: [](install-mamba). [Google also knows the answer](https://www.google.com/search?q=is+it+true+that+mamba+is+like+conda+but+faster).\n",
    "```\n",
    "\n",
    "```{dropdown} There are different kinds of python interpreters. \"ipython\" is one one of them.\n",
    "\n",
    "**Answer**: Correct. [Google knows the answer](https://www.google.com/search?q=is+it+true+that+ipython+is+a+python+interpreter).\n",
    "```\n",
    "\n",
    "```{dropdown} numpy is part of the python standard library.\n",
    "\n",
    "**Answer**: Wrong. [Google knows the answer](https://www.google.com/search?q=is+numpy+part+of+the+python+standard+library).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Multiple choice: Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "**Which of the affirmations about the code snippet below are true?**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "a = np.arange(12).reshape((3, 4))\n",
    "b = a * 2\n",
    "nz = np.nonzero(a > 8)\n",
    "b[nz] = a[nz]\n",
    "```\n",
    "\n",
    "Wrong answers are penalized! In case of doubt you may choose not to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "```{dropdown} This code produces an array b which doubles the values in a, except where the values are strictly larger than 8. In this case, the values are not doubled.\n",
    "\n",
    "**Answer**: correct. Running the code might have been the best strategy to answer this.\n",
    "\n",
    "```\n",
    "\n",
    "````{dropdown} The same result can be obtained using boolean indexing.\n",
    "\n",
    "**Answer**: Correct. This would be the code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "a = np.arange(12).reshape((3, 4))\n",
    "b = a * 2\n",
    "larger_than_8 = a > 8\n",
    "b[larger_than_8] = a[larger_than_8]\n",
    "```\n",
    "\n",
    "Lecture notes on the topic: [](bool-ind).\n",
    "\n",
    "````\n",
    "\n",
    "```{dropdown} The code uses boolean indexing.\n",
    "\n",
    "**Answer**: Wrong. It uses positional indexing, by asking first *where* (at which position) are the elements which are larger than 8, and then using these positions to index `a` and `b`: therefore, positional indexing. Lecture notes on the topic: [](pos-ind).\n",
    "```\n",
    "\n",
    "```{dropdown} The code uses positional indexing.\n",
    "\n",
    "**Answer**: Correct. It uses positional indexing, by asking first *where* (at which position) are the elements which are larger than 8, and then using these positions to index `a` and `b`: therefore, positional indexing. Lecture notes on the topic: [](pos-ind).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Coding: Taylor function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Write a function called `taylor_sin` which computes the Taylor approximation of the sinus function:\n",
    "\n",
    "$$\n",
    " \\sin(x) = \\sum_{i=0}^n (-1)^i\\frac{x^{2i+1}}{(2i+1)!} = \\frac{x}{1!} - \\frac{x^3}{3!} + \\frac{x^5}{5!} \\mp \\dots\n",
    "$$\n",
    "\n",
    "With ! denotating the number's factorial. The inputs n and x should be given as argument to the function. Quantify the uncertainty of the approximation for x = π / 2 and n=5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def taylor_sin(x, n):\n",
    "    output = 0\n",
    "    for i in range(n+1):\n",
    "        output += (-1)**i * x**(2*i+1) / math.factorial(2*i+1)\n",
    "    return output\n",
    "\n",
    "x = math.pi / 2\n",
    "\n",
    "\n",
    "true_value = math.sin(x)\n",
    "\n",
    "n = 5\n",
    "print(f'Error for x = π / 2 and n={n}: {taylor_sin(x, n) - true_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Other values of n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [1, 3, 5, 7]:\n",
    "    print(f'Error for x = π / 2 and n={n}: {taylor_sin(x, n) - true_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Notebook: Greenland "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Here is a link to a .csv file to download:\n",
    "\n",
    "https://cluster.klima.uni-bremen.de/~fmaussion/teaching/inpro/greenland.csv\n",
    "\n",
    "It contains data from an automatic weather station at the North of the Greenland ice-sheet. It contains the measured incoming (\"down\") and outgoing (\"up\") shorwtave radiation at the station.\n",
    "\n",
    "Your task is to return a Jupyter Notebook (upload button) which does the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "**1. Read the csv file using pandas, and make sure the index of the `DataFrame` has the datatype `DatetimeIndex`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://cluster.klima.uni-bremen.de/~fmaussion/teaching/inpro/greenland.csv', index_col=0, parse_dates=True)\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "**2. For both data columns, replace missing values with NaN (missing values can be found easily)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(-999., np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "**3. Select data from the years 2010 to 2015 only (i.e. discard the incomplete year 2016). From now on, we only analyze data from 2010 to 2015.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc['2010':'2015']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**4. Compute the average albedo at this location, which is computed as: $\\sum SW_{up} / \\sum SW_{down}$ over the entire time period from 2010 to 2015.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "albedo = df['ShortwaveRadiationUp_Cor(W/m2)'].sum() / df['ShortwaveRadiationDown_Cor(W/m2)'].sum()\n",
    "albedo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "**5. Compute the monthly average radiation from the data, and plot it on a line plot (see example below). Tip: if you don't manage this question, you can still do the rest of the exercise independently.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample('MS').mean().plot(); \n",
    "plt.ylabel('W m$^{-2}$'); \n",
    "plt.title('Monthly average radiation');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "**6. Compute the daily cycle of radiation (average hourly radiation) for the month of June. I expect a DataFrame with index of type integer, with values from 0 to 23.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.loc[df.index.month == 6]\n",
    "dfs = dfs.groupby(dfs.index.hour).mean()\n",
    "dfs.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "**7. Using the hourly average data from question 6: at what time of day in the incoming radiation largest? What is its value?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['ShortwaveRadiationDown_Cor(W/m2)'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['ShortwaveRadiationDown_Cor(W/m2)'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['ShortwaveRadiationDown_Cor(W/m2)'].loc[dfs['ShortwaveRadiationDown_Cor(W/m2)'] == dfs['ShortwaveRadiationDown_Cor(W/m2)'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "**8. Plot the daily cycle of hourly incoming radiation in January, March and July as line plot. Tip: the x-axis of the plot should show the hour of the day, from 0 to 23. Add the outgoing radiation as a dashed line (see example plot below).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.loc[df.index.month == 7]\n",
    "dfs = dfs.groupby(dfs.index.hour).mean()\n",
    "dfs['ShortwaveRadiationDown_Cor(W/m2)'].plot(label='July', color='C0');\n",
    "dfs['ShortwaveRadiationUp_Cor(W/m2)'].plot(label='', linestyle='--', color='C0');\n",
    "\n",
    "\n",
    "dfs = df.loc[df.index.month == 3]\n",
    "dfs = dfs.groupby(dfs.index.hour).mean()\n",
    "dfs['ShortwaveRadiationDown_Cor(W/m2)'].plot(label='March', color='C1');\n",
    "dfs['ShortwaveRadiationUp_Cor(W/m2)'].plot(label='', linestyle='--', color='C1');\n",
    "\n",
    "dfs = df.loc[df.index.month == 1]\n",
    "dfs = dfs.groupby(dfs.index.hour).mean()\n",
    "dfs['ShortwaveRadiationDown_Cor(W/m2)'].plot(label='January', color='C2');\n",
    "dfs['ShortwaveRadiationUp_Cor(W/m2)'].plot(label='', linestyle='--', color='C2');\n",
    "\n",
    "plt.legend(); plt.ylabel('Shortwave (W m$^{-2}$)'); plt.xlabel('Hour of day'); plt.title('Radiation at Greenland station (down and up)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Notebook: Peru "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Here is a code snippet which loads 2D data from the web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "# Parse the given url\n",
    "url = 'https://cluster.klima.uni-bremen.de/~fmaussion/teaching/inpro/chirps_peru_avg.npz'\n",
    "req = urlopen(Request(url)).read()\n",
    "with np.load(BytesIO(req)) as data:\n",
    "    annual_prcp = data['annual_prcp']\n",
    "    lon = data['lon']\n",
    "    lat = data['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Copy this code snippet and paste it in an empty notebook. Execute the code.\n",
    "\n",
    "`annual_prcp` is a numpy array of shape (lat, lon) and represents the average annual precipitation (unit mm/d) over the country of Peru.\n",
    "\n",
    "Upload a Jupyter Notebook (upload button) which addresses the following tasks. *Tip: many of the tasks can be done independently from the other ones! Pick the ones you know how to do quickly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "**1. Compute `annual_prcp_myr`, the average annual precipitation in units meter per year (m yr-1). For this you can assume that a year has 365.25 days on average.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_prcp_myr = annual_prcp / 1000 * 365.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "**2. Plot the 2D array `annual_prcp_myr` with the `blues` colormap. Add a colorbar and ticks and axis labels (Lon, Lat). *Tip: if you want your map to not be squeezed, you may have to use ax.set_aspect('equal') after you plotted the data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "im = ax.pcolormesh(lon, lat, annual_prcp_myr, shading='nearest', cmap='Blues');\n",
    "ax.set_aspect('equal');\n",
    "f.colorbar(im, label='mm/yr'); ax.set_xlabel('Lon'); ax.set_ylabel('Lat'); ax.set_title('Average precipitation in Peru');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "**3. Count the number of pixels in `annual_prcp_myr` which have a precipitation value over 5 m yr-1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "(annual_prcp_myr > 5).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "**4. Create the array `annual_prcp_myr_subset`, which is a subset of the `annual_prcp_myr` array selected between the indices  217 and 316 in latitude, and the indices 37 and 176 in longitude. The resulting 2D array should be of shape (99, 139).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_prcp_myr_subset = annual_prcp_myr[217:316, 37:176]\n",
    "annual_prcp_myr_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "**5. Now create the arrays `lon_subset` and `lat_subset`, which are the corresponding coordinates selected over the same indices. `lon_subset` should have the shape (139,) and `lat_subset` should have the shape (99,).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_subset = lon[37:176]\n",
    "lon_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_subset = lat[217:316]\n",
    "lat_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "**6. Now average `annual_prcp_myr_subset` over the latitudes to create an array of shape (139,) named `annual_prcp_myr_subset_lat`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_prcp_myr_subset_lat = annual_prcp_myr_subset.mean(axis=0)\n",
    "annual_prcp_myr_subset_lat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "**7. Plot `annual_prcp_myr_subset_lat` as a line plot as the example plot below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lon_subset, annual_prcp_myr_subset_lat);\n",
    "plt.title('Average precipitation between 3°S and 8°S in Peru.')\n",
    "plt.xlabel('Longitude'); plt.ylabel('m yr$^{-1}$'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "**8. Using a numpy function you learnt during the lecture, find out why I chose the indices 217 and 316 to select data for latitudes between -3° and -8°.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.nonzero((lat < -3) & (lat >-8))[0]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.min(), p.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
